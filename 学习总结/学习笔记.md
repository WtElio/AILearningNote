

## 一、激活函数和损失函数问题

### Sigmoid为什么不用做多分类？

① 因为sigmoid激活函数数值是在（0，1）之间概率值，只能对输出结果做是目标和不是目标的区分。并且这些预测概率值之间是相互独立的。但事实上多分类问题中，这些概率之间应该是相关联的。

② sigmoid激活函数也可以用于多标签分类问题，不同标签设置不同阈值区分，超出某个阈值就判断为什么标签。sigmoid做多标签分类时，损失函数应该设计为BCELoss。

### Sigmoid和Softmax的使用？

① 二分类任务时，既可以用Sigmoid+BCELoss+输出通道=1，也可以用Softmax+BCELoss+输出通道=2。

② 多分类任务时，用Softmax+CELoss+输出通道=n。

（1）任务决定模型的输出通道维度，（2）输出通道维度决定用sigmoid还是softmax(不考虑多标签)，（3）sigmoid和softmax决定损失函数。

### 常见激活函数优缺点？

<center class="half">
<img src=".\image\Snipaste_2023-07-16_08-30-20.jpg" width=250/>
<img src=".\image\Snipaste_2023-07-16_08-31-15.jpg" width=200/>
<img src=".\image\Snipaste_2023-07-16_08-42-19.jpg" width=200/>
<img src=".\image\Snipaste_2023-07-16_08-32-15.jpg" width=300/>
</center>


<center class="half">
<img src=".\image\Snipaste_2023-07-16_09-19-09.jpg" width=250/>
<img src=".\image\Snipaste_2023-07-16_09-22-01.jpg" width=200/>
<img src=".\image\Snipaste_2023-07-16_09-20-30.jpg" width=200/>
</center>



#### Tanh激活函数

优点：① 关于原点对称、均值为0通常能更快收敛。② 值区间在[-1，1]，可以将值映射到更大的范围，提升模型的表达能力。

缺点：① 在某些区间梯度饱和，存在梯度消失问题。

#### Sigmoid激活函数

优点：① 输出在【0，1】之前，可被用作表示概率值和归一化。② 连续函数便于求导

缺点：① 在某些区间梯度饱和，存在梯度消失问题。

#### Softmax激活函数

优点：① 将一组任意实数转换为概率分布，适用于多分类问题，可以将输出解释为各个类别的概率。
缺点：① 对于输入数据中的极大值敏感，可能导致数值不稳定的问题。

#### Relu激活函数

优点：① 计算简单，能够有效地解决梯度消失的问题，适用于深度神经网络。
缺点：① 在输入数据为负数时，梯度为0，可能导致神经元死亡的问题。

#### Mish激活函数

优点：① 综合了Relu和Tanh两种激活函数的优势，在输入＞0反向求导迅速并且不会梯度消失，在输入＜0有很强的非线性表达能力。

缺点：① 整体计算复杂度较高，可能导致训练速度较慢。

#### Swish激活函数

优点：① 综合了Relu和Sigmoid两种激活函数的优势，在输入＞0反向求导迅速并且不会梯度消失，在输入＜0有很强的非线性表达能力。

缺点：① 整体计算复杂度较高，可能导致训练速度较慢。

### MSELoss为什么不适合做分类问题？

① 当MSELoss和Sigmoid函数一起使用时，由于Sigmoid函数在靠近函数两端时梯度值会很小，可能会出现梯度消失。

② 首先，分类问题本质上就是概率问题，分类损失本质上就是求解真实概率分布和预测概率分布之间的差异，和几何上的欧式距离无关，并且分类问题的label值是0、1、2这种离散的在欧氏空间无意义的值，所以MSELoss不适合分类问题。

③ 对于分类问题，如果使用MSELoss，那么在正确分类的情况下，损失函数的梯度接近于零，这会导致模型在训练过程中更新缓慢，影响模型的收敛速度和性能。（公式决定）

### 常见损失函数优缺点？

<center class="half">
<img src=".\image\Snipaste_2023-07-16_09-49-33.jpg" width=500/>
</center>



#### L1 loss（平均绝对误差损失）

优点：① 梯度恒等	缺点：① x=0拐点处梯度变化比较大，震荡厉害

#### L2 loss（均方差损失）

优点：① 拐点处梯度放缓	缺点：① 在远离x=0处容易产合梯度爆炸

#### Smooth L1

优点：在x=0处梯度放缓，远离x=0处梯度恒等，不会产生梯度爆炸。

#### IOU loss

为什么使用IOU loss：传统的框的回归仅仅考虑四个变量（x1,y1,x2,y2）并且认为这四个变量是独立的，但是事实上，这四个变量之间相互关联，简单的计算四个变量的回归无法真正表征框的好坏，将预测框与GT框之间的iou引入回归loss则很好的解决了这一问题。

 <center class="half">
<img src=".\image\Snipaste_2023-07-16_10-11-11.jpg" width=300/>
<img src=".\image\Snipaste_2023-07-16_10-12-17.jpg" width=300/>
<img src=".\image\Snipaste_2023-07-16_10-12-33.jpg" width=300/>     
</center>




好的IOU loss需要考虑重叠度、中心点距离、长宽比。

#### Focal loss

Focal Loss的目标：通过控制正负样本和难易样本损失的权重，使得模型预测不会有偏向，更具泛化性。

 <center class="half">
<img src=".\image\Snipaste_2023-07-16_10-35-30.jpg" width=400/>  
<img src=".\image\Snipaste_2023-07-16_10-38-52.jpg" width=300/>     
</center>



其中引入参数at解决了正负样本不平衡的问题，(1-pt)^r解决了难易样本不均衡的问题。

#### Triplet loss

Triplet Loss的目标：Triplet Loss的目标是使得相同标签的特征在空间位置上尽量靠近，同时不同标签的特征在空间位置上尽量远离，同时为了不让样本的特征聚合到一个非常小的空间中要求对于同一类的两个正例和一个负例，负例应该比正例的距离至少远margin。如下图所示：

 <center class="half">
<img src=".\image\Snipaste_2023-07-16_10-50-09.jpg" width=500/>  
<img src=".\image\Snipaste_2023-07-26_08-06-48.jpg" width=500/>  
<img src=".\image\Snipaste_2023-07-26_08-09-03.jpg" width=500/>  
<img src=".\image\Snipaste_2023-07-26_08-10-01.jpg" width=500/>  
<img src=".\image\Snipaste_2023-07-26_08-10-20.jpg" width=500/> 
<center>


经过Triplet loss学习以后同类的Positive样本和Anchor的距离越来越近而不同类的Negative样本和Anchor的距离越来越远。
缺点：训练数据相当复杂，也增加了计算的复杂度。

#### Center loss

CenterLoss的目标是减小类内距离，使得同一类别样本在特征空间中更加紧密，它通过引入类别中心并最小化样本到其类别中心的距离来实现这一目标。

Center Loss的更新步骤如下：

① 首先初始化各个类别的中心点。② 在前向传播阶段，计算每个样本到其类别中心的距离。③ 在反向传播阶段，根据损失函数的梯度更新网络参数。④ 同时，也需要更新每个类别的中心。具体来说，对于每个类别c，我们计算该类别所有样本的平均特征向量，然后将其作为新的类别中心。

缺点：类间距离受初始化类别中心点影响，有时初始化不好的情况下，不同类样本特征分不开。

#### ArcFace loss

ArcFaceLoss的目标是增大类间距离，即使得不同类别的样本在特征空间中更加分散。它通过引入角度边界并最大化类别间的角度来实现这一目标。

 <center class="half">
<img src=".\image\Snipaste_2023-07-16_21-15-11.jpg" width=600/>
<img src=".\image\Snipaste_2023-07-16_21-15-31.jpg" width=600/>   
</center>


------



## 二、常见零散问题

### 详解Batchnorm、Normalize、归一化的区别和作用？

<font color=Blue>Batchnorm：</font>通常用于神经网络的某些层当中。深层神经网络在做非线性变换前的激活输入值h=Wx+b在网络逐步加深或者训练过程中，其分布会逐渐偏移，发生变动。由此输入到激活函数的值在某些区间内梯度消失了（如sigmoid激活在x>6时），使得神经网络训练过程中收敛越来越慢。BN就是通过一定的规范化手段，把每层神经网络任意神经元这个输入值的分布强行拉回到均值为0方差为1的标准正态分布。这样使得激活输入值落在非线性函数对输入比较敏感的区域，这样输入的小变化就会导致损失函数较大的变化，并且使得数据具有相同分布，可使用更大的学习率和更多的激活函数从而加快模型收敛。

<img src=".\image\Snipaste_2023-07-21_11-15-45.png" alt="Snipaste_2023-07-21_11-15-45" style="zoom:50%;" />

数据具有相同分布---1》使用更大的学习率和更多的激活函数 2》对权重初始化不在敏感

<font Color=Blue>Batchnorm作用：</font>① 加快网络的训练与收敛的速度	② 解决梯度爆炸抑制梯度消失	③ 防止过拟合

<font Color=Blue>Normalize</font>：首先标准化方法为减均值除以标准差，体现了去同存异的思想，而同一批数据中相同的大多都是噪声，所以标准化有去噪的作用。其次把数据分布限制到标准正态分布上，一定程度上可以加快梯度下降，并且防止梯度消失和梯度爆炸。

<font Color=Blue>归一化：</font>归一化是众多方法的总称，具有Normlize的全部作用。对输入数据进行处理，使得数据的取值范围在0到1之间或者-1到1之间。这有助于消除不同特征之间的量纲差异，提高模型的训练效果。

### 过拟合产生的原因、如何防止过拟合、如何防止欠拟合？

**性质1** a1,a2,⋯,an 线性相关 ⟺ 显然，其中必有某个向量是其它向量的线性组合。

数学：产生过拟合的本质原因就是神经网络的w和x达到了比较高程度的线性相关，达到线性相关说明有冗余，即过拟合了。

数据和模型：数据和模型复杂程度不匹配。

结果：过拟合是指模型在训练数据上表现良好，但在测试数据上表现较差的情况。

<font Color=Blue>如何防止过拟合：</font>① 数据增广增强	② 简化模型和增加噪声	③ 正则化(L2)	④ Batchnorm	⑤ Early Stopping	⑥ Dropout	⑦ Maxpool

<font Color=Blue>如何防止欠拟合：</font>① 添加更加丰富的特征	② 减少正则化参数	③ 增加网络复杂度

### 什么是前向传播、反向传播？

<font Color=Blue>前向传播：</font>前向传播是指将输入数据传递给网络，并通过每一层的神经元和激活函数，计算出网络的输出。这个过程从输入层开始，经过所有隐藏层，最后到达输出层。在每一层，数据会与权重相乘，然后加上偏置，最后通过激活函数进行非线性变换。

<font Color=Blue>反向传播：</font>反向传播是指在前向传播的基础上，通过计算损失函数的梯度，并将这个梯度反向传播回网络的每一层，来更新网络的权重和偏置。这个过程从输出层开始，经过所有隐藏层，最后到达输入层。在每一层，都会根据梯度和学习率来更新权重和偏置，以减小损失函数的值。

### 梯度下降算法、随机梯度下降算法、前向传播、反向传播算法？

<font Color=Blue>梯度下降算法：</font>梯度下降是一种优化算法，用于更新神经网络的权重以最小化损失函数。它通过计算损失函数相对于每个权重的梯度，来确定梯度的方向。然后根据学习率（learning rate）的大小，按照梯度的反方向更新权重，以使损失函数的值逐渐减小。梯度下降是一个迭代过程，重复更新权重直到收敛或达到预定的迭代次数。步骤如下：

① 初始化参数：选择初始的模型参数值。

② 计算损失函数：使用当前的模型参数计算损失函数的值，该函数衡量模型预测值与实际值之间的差异。

③ 计算梯度：计算损失函数对于每个模型参数的梯度，即损失函数对于每个参数的偏导数。

④ 更新参数：使用梯度和学习率来更新模型参数。学习率决定了每次迭代中参数更新的步长。

⑤ 重复步骤2至4：重复计算损失函数、梯度和参数更新的步骤，直到达到预定的迭代次数或满足收敛条件。

⑥ 输出最优参数：在迭代完成后，输出最优的模型参数，这些参数使得损失函数达到最小值。

<font Color=Blue>随机梯度下降算法：</font>随机梯度下降中的随机指的是从训练样本中随机抽取一个样本计算梯度，更新模型参数。相对于普通梯度下降算法减小了内存开销，加快了运算速度，但也影响了SGD算法的稳定性。

<img src=".\image\Snipaste_2023-07-22_21-21-56.jpg" alt="Snipaste_2023-07-22_21-21-56" style="zoom:25%;" />

<font Color=Blue>前向反向传播算法：</font>前向传播是指从输入数据开始，通过神经网络的层级结构将数据传递到输出层的过程。每个神经元将来自上一层神经元的输入与权重相乘并进行求和，然后通过激活函数处理以产生输出。反向传播是指计算损失函数对网络中每个权重的梯度，并使用梯度下降算法来更新权重，以最小化损失函数的值。反向传播通过链式法则计算梯度，从输出层反向传播到输入层。反向传播步骤如下：

① 前向传播：将输入数据通过神经网络进行前向传播，计算每一层的输出值。

② 计算损失：使用损失函数比较神经网络的输出和真实标签，计算损失值。

③ 反向传播：从输出层开始，计算每一层的梯度。首先计算输出层的梯度，然后逐层向前计算隐藏层的梯度。

④ 参数更新：使用梯度下降算法或其他优化算法，根据梯度信息更新神经网络的参数。

⑤ 重复步骤1至4：重复进行前向传播、损失计算、反向传播和参数更新的步骤，直到达到预定的迭代次数或满足收敛条件。

好的视频：https://www.bilibili.com/video/BV1oY411N7Xz?vd_source=6bf8a2ceef58918e445129ceac9c7256

### 解释自适应学习率优化算法，如Adagrad、RMSprop和Adam?

自适应学习率优化算法通常指的是根据参数历史梯度自动更新学习率的算法。

 <center class="half">
<img src=".\image\Snipaste_2023-07-22_21-26-49.jpg" width=600/>
<img src=".\image\Snipaste_2023-07-22_21-27-53.jpg" width=300/>   
</center>

注：g为梯度，引入参数r为历史梯度积累量，s为自适应动量

<font Color=Blue>Adagrad：</font>通过历史梯度积累量控制学习率的更新，当r越大时学习率自动减小，而r比较小时学习率会比较大。但是这个情况下学习率只跟梯度有关，那么有时会使得学习率过早地变小，因此又提出了RMSprop算法。

<font Color=Blue>RMSprop：</font>RMSprop算法引入了一个可以手动调节的p来控制优化过程。

<font Color=Blue>Adam：</font>Adam算法中，综合了动量和自适应学习率两种方法计算自适应学习率。

动量概念参考下图：

<img src=".\image\Snipaste_2023-07-22_21-21-20.jpg" alt="Snipaste_2023-07-22_21-21-20" style="zoom:40%;" />

### 什么是学习率衰减，Pytorch中有哪些衰减方法?

等步长衰减—torch.optim.lr_scheduler.StepLR：每经过一定的epoch数，将学习率乘以一个衰减因子gamma。

多步长衰减—torch.optim.lr_scheduler.MultiStepLR：在预定义的milestones（里程碑）处，将学习率乘以一个衰减因子gamma。

指数衰减—torch.optim.lr_scheduler.ExponentialLR：每个epoch都将学习率乘以一个衰减因子gamma。

余弦退火衰减—torch.optim.lr_scheduler.CosineAnnealingLR：使用余弦退火的方式调整学习率，可以设置一个周期数T来控制学习率的变化。

自适应调整学习率衰减—torch.optim.lr_scheduler.ReduceLROnPlateau：根据验证集的表现动态地调整学习率，当验证集的指标不再改善时，将学习率乘以一个衰减因子。

自定义函数衰减—torch.optim.lr_scheduler.LambdaLR：根据给定的函数来调整学习率，可以自定义学习率的变化规律。

### CNN在图像上做特征提取为什么会优于MLP？

① CNN形状（N,C,H,W）MLP形状（N,V）表征图象的数据维度越高，特征信息越丰富，越有利于模型特征提取。

② CNN特性局部连接、权值共享。MLP每次提取的是全局信息，而CNN每次提取的是不同的局部信息，对于图像来说局部的细节信息更能突显差异，包含了更多的特征。

③ MLP的bias远多于CNN，训练时难以训练，稳定性比较差。

### 详解梯度消失和梯度爆炸？

<font Color=Blue>梯度消失：</font>梯度消失是由于神经网络在反向传播过程中，较早层的梯度值变得很小，导致在链式求导梯度连乘过程中每层的导数值很小，当使用这些很小的导数去更新参数时，参数更新就变得异常缓慢，甚至无法更新。

<font Color=Green>导致梯度消失有两种情况：</font> ① 不合适的参数初始化	② 不合适的激活函数。最主要还是激活函数的选择，因为这两种情况都归咎于激活函数的输入值落入到了激活函数高阶导（可以理解为梯度）为零或很小的区域。

<font Color=Green>如何避免梯度消失：</font>① 选择合适的激活函数	② 合理的初始化参数	③ 加入BatchNorm	④ 梯度裁剪	⑤ 残差连接

<font Color=Blue>梯度爆炸：</font>梯度爆炸是由于神经网络在反向传播过程中，较早层的梯度值变得很大，导致在链式求导梯度连乘过程中每层的导数值很大，当使用这些很大的导数（也是梯度）去更新参数时，参数更新就变得异常剧烈，甚至无法更新。

<font Color=Green>导致梯度爆炸有两种情况：</font> ① 不合适的参数初始化	② 学习率过大。其根本原因还是在于网络在反向传播过程导数的连乘中存在梯度放大的情况。

<font Color=Green>如何避免梯度爆炸：</font>① 选择合适的学习率	② 合理的初始化参数	③ 梯度裁剪

### NMS算法去重原理和步骤？

<img src="C:\Users\Administrator\Desktop\学习文档\学习总结\image\Snipaste_2023-07-25_18-51-48.png" alt="Snipaste_2023-07-25_18-51-48" style="zoom:60%;" />

------



## 三、模型评价指标

模型评价通常从性能指标和精度指标两方面去考量。

<font Color=Blue>性能指标：</font>➢模型运行的平台有关➢ 性能一般有两个指标：参数量和计算量➢ 性能指标单位有：floaps/帧率

<font Color=Blue>精度指标：</font>➢混淆矩阵➢Precision、Recall➢PRC、F1-score➢ROC、AUC➢IOU、mAP

##### 目标分类指标：混淆矩阵、P-R曲线和F1-Score、ROC与AUC

 <center class="half">
<img src=".\image\Snipaste_2023-07-16_18-45-01.jpg" width=300/>
<img src=".\image\Snipaste_2023-07-16_18-47-54.jpg" width=300/>
<img src=".\image\Snipaste_2023-07-16_18-49-25.jpg" width=300/>     
</center>



##### 目标检测指标：Iou、mAP

 <center class="half">
<img src=".\image\Snipaste_2023-07-16_18-52-02.jpg" width=400/>
<img src=".\image\Snipaste_2023-07-16_18-52-14.jpg" width=400/>   
</center>


------




## 四、常见模型

### 分类模型

#### Res Net

<img src=".\image\Snipaste_2023-07-21_18-23-40.png" alt="Snipaste_2023-07-21_18-23-40" style="zoom:150%;" />

<font Color=Blue>Residual Block：</font>Resnet中含有两种residual block。第一种是普通的两层3×3卷积卷积加一个跳接结构，第二种引入了瓶颈残差块，它由一个1×1卷积、3×3卷积、1×1卷积加一个跳接结构构成。瓶颈残差块这种结构可以有效地减少参数量，提高运算效率

<font Color=Blue>Skip Connection：</font>跳接结构是resnet的核心思想，能有效地解决梯度消失问题。

#### Dense Net

 <center class="half">
<img src=".\image\Snipaste_2023-07-21_21-41-36.jpg" width=450/>
<img src=".\image\Snipaste_2023-07-21_21-42-44.jpg" width=450/>   
</center>
<font Color=Blue>Dense Block：</font>Dense Block是由多个密集连接（Dense Connection）的层组成的模块。每个层的输出都会直接传递给后续所有层作为输入，输出是通过将前面几层的通道和本层输出的通道做叠加实现的。并且Dense Block中采用了瓶颈结构，能有效地降低参数量，加快运算效率。这种密集连接的设计使得信息可以更好地在网络中流动，促进了特征的重用和梯度的传播。

<font Color=Blue>Growth Rate：</font>在DenseNet中，"growth rate"（增长率）是一个超参数，用于控制每个Dense Block中每个层输出的通道数。增长率决定了每个层生成的特征图的大小。

<font Color=Blue>Transition Layer：</font>过渡层用于减少特征图的维度，通过使用1x1卷积和平均池化来降低通道数和空间分辨率。

#### Mobile Net

 <center class="half">
<img src=".\image\Snipaste_2023-07-22_08-51-48.jpg" width=450/>
<img src=".\image\Snipaste_2023-07-22_08-52-05.jpg" width=300/>   
</center>

MobileNet有三个版本。V1中引入了深度可分离卷积，V2在V1基础上提出了倒残差结构和线性瓶颈概念，V3在V2基础上提出了SE通道注意力机制以及新的激活函数h-swish。下面详解MobileNet V2网络结构和三个版本所引出的一些新方法。

<font Color=Blue>深度可分离卷积：</font>深度可分离卷积包含深度卷积和逐点卷积两个步骤。首先，深度卷积对输入的每个通道进行单独的卷积操作，然后将各个通道的卷积结果进行堆叠，生成一个具有相同深度（通道数不变）的特征图。其次，逐点卷积应用一个1x1的卷积核，对每个通道上的特征图进行卷积操作。这个1x1的卷积核可以看作是将不同通道之间的特征进行线性组合。深度可分离卷积参数量减少了1/k倍，提升了模型计算效率。

<font Color=Blue>倒残差结构：</font>对比ResNet网络残差结构中的1×1卷积用来将通道降维，而MobileNet V2中1×1卷积用来将通道升维，这样使用DW卷积可以提取更多的信息。

<font Color=Blue>线性瓶颈：</font>线性瓶颈结构主要用于在深度可分离卷积之后，用于减少特征的通道数，从而降低模型的复杂性和计算量。主要作用① 减少特征通道数② 原来的Relu激活函数会丢失大量低维特征信息，使用线性激活可以保持特征的信息（具体操作直接使用nn.Linear）

<font Color=Blue>SE通道注意力机制：</font>

 <center class="half">
<img src=".\image\Snipaste_2023-07-22_09-37-10.jpg" width=450/>
<img src=".\image\Snipaste_2023-07-27_10-14-29.png" width=450/>         
<center>


总体步骤就是如图一先压缩再激励最后Scale，压缩激励如图二其实是在计算各个通道的权重，最后通过Scale将该权重向量和原始输入相乘得到重标定后的特征图。

<font Color=Blue>H-Swish激活函数：</font>见一中常见激活函数。

#### Google Net

 <center class="half">
<img src=".\image\Snipaste_2023-07-22_10-28-56.jpg" width=450/>
<img src=".\image\Snipaste_2023-07-22_10-31-04.jpg" width=400/>   
</center>

<font Color=Blue>Inception：</font>Inception模块包含多个版本。

Inception V1：

初始版本，包含1x1、3x3、5x5的卷积和3x3的最大池化，然后在通道维度上进行拼接。

Inception V2：

在Inception V1的基础上，引入了两个概念：1x1卷积用于降维，减少计算量；将5x5卷积替换为两个连续的3x3卷积，减少参数量。

Inception V3：

在Inception V2的基础上，进一步将3x3卷积替换为1x3和3x1的卷积，减少参数量和计算量。

Inception V4：

图二在Inception V3的基础上，引入了ResNet的残差连接，提高了模型的深度。

不同尺度的卷积和池化通过加padding来使得他们的HW保持一致。

### 分割模型

#### U-Net

<img src=".\image\Snipaste_2023-07-22_10-33-54.jpg" alt="Snipaste_2023-07-22_10-33-54" style="zoom:50%;" />

Unet网络结构主要有两部分组成。① 编解码结构提取特征、还原特征。 ② 跳接结构做信息补全

###### 总结：

U-net通常用于普通分割和语义分割，具体设计如下

<font Color=Green>二分类：</font>使用MSEloss则无需使用输出函数，输出通道为1，标签为二值图（N,1,H,W）。使用BCELoss则需要使用sigmoid函数，输出通道为1，标签为二值图（N,1,H,W），当标签为灰度图时要对pred做squueze（dim=1）处理。使用BCEWithLogitsLoss唯一不同的就是不需要使用sigmoid函数。

<font Color=Green>多分类：</font>多分类有两种处理方法。① 使用带颜色RGB的标签，模型直接学习标签的颜色作为分类，pred形状为（N,3,H,W），标签形状（N,3,H,W）。② pre形状为（N,Num_classes,H,W），标签形状为（N,H,W）其中标签里的每个像素值是该像素的分类，值范围在[0,Num_classes-1]内。由于Pytorch中自带Softmax函数，所以不再需要输出函数。

### 检测模型

#### RCNN系列

##### RCNN

 <center class="half">
<img src=".\image\Snipaste_2023-07-22_16-30-47.jpg" width=450/>
<img src=".\image\Snipaste_2023-05-25_16-43-11.png" width=400/>   
</center>
① Selelctive Search算法通过图像分割的方法得到一些原始区域，然后使用一些合并策略将这些区域合并，得到一个层次化的区域结构，而这些结构里可能包含目标。

② 将一步骤中框中的2000张图片缩放到227×227的大小，输入到预先训练好的CNN网络中，得到2000×4096的矩阵。

③ 将2000×4096的特征矩阵乘以20个SVM分类器（2000×20）当中，得到一个2000×20的矩阵，该矩阵中，2000是框的数量，20是每个框对应的是哪个类的概率值。

④ 这里首先需要用到nms算法去除重复框，具体步骤如下：

寻找2000×20矩阵中每一类得分最高的框，利用该框和其他框求iou，iou大于阈值的去除掉（因为可能重复），再在保留下来的集合里再取得分最高的框和其他做iou重复执行这个步骤，就有可能去掉所有重复框。

⑤ 回归框坐标反算，参考Faster RCNN

<font Color=Red>缺点：</font>计算量太大。步骤一中2000个分割得到的图片都需要输入到CNN网络中，导致计算量非常大。

##### FastRCNN

 <center class="half">
<img src=".\image\Snipaste_2023-05-25_16-28-42.png" width=450/>
<img src=".\image\Snipaste_2023-05-25_16-42-15.png" width=400/>   
</center>
① Region Proposal（Seletive Search生成候选框）

② 将原图送到CNN特征提取网络中，得到特征图。再将步骤①的候选框映射到特征图当中，得到对应区域的特征矩阵。

③ 将每个特征矩阵通过ROI pooling层缩放到7×7大小的特征图。

④ 将特征图分两部分展平的到一部分关于分类的输出，另一部分关于回归的输出。

<font Color=Red>优点：</font>解决了RCNN中每个分割得到的区域都需要送到CNN网络中的问题，减少了计算量。

​			利用Softmax作为分类，将特征提取和分类回归放入了同一个网络，减少了磁盘的开销，训练简单。

<font Color=Red>缺点：</font>模型先要采用Selective Search选取候选框，所以仍然不是完整意义的端到端模型，训练时间上还有待提高。

##### FasterRcnn

 <center class="half">
<img src=".\image\Snipaste_2023-08-03_16-23-24.png" width=550/> 
<img src=".\image\Snipaste_2023-07-22_16-32-56.jpg" width=450/>   
</center>

Faster RCNN的结构主要有三大部分组成。第一部分是共享卷积层backbone提取特征，第二部分是候选区域生成网络-RPN，第三部分是对候选区域进行分类的网络-classifier。

① 输入图像经过共享卷积层，对全图提取特征，得到一个特征图。

② 得到的特征图输入到RPN网络中。滑动窗口在特征图上滑动，为每个位置生成9种预先设置好长宽比与面积的目标框(文中叫做anchor)。RPN要做的事情有两个，第一个是判断anchor到底是前景还是背景，意思就是判断这个anchor到底有没有覆盖目标，第二个是为属于前景的anchor进行第一次坐标修正。

③ 特征被共享卷积层一次性提取。因此，对于每个RoI而言，需要从共享卷积层上摘取对应的特征，并且送入全连接层进行分类。因此，RoI Pooling主要做了两件事，第一件是为每个RoI选取对应的特征，第二件事是为了满足全连接层的输入需求，将每个RoI对应的特征的维度转化成某个定值。

<font Color=Red>优点：</font>Faster RCNN实现了真正意义上的端到端训练。

##### MaskRcnn

三种网络具体内容见：[RCNN, Fast R-CNN 与 Faster RCNN理解及改进方法 - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/55856134)

MaskRCNN优秀博客：[实例分割模型Mask R-CNN详解：从R-CNN，Fast R-CNN，Faster R-CNN再到Mask R-CNN_jiongnima的博客-CSDN博客](https://blog.csdn.net/jiongnima/article/details/79094159)。这篇博客很好的阐释了RPN网络的原理。

#### MTCNN和人脸识别

 <center class="half">
<img src=".\image\Snipaste_2023-07-23_08-19-35.jpg" width=450/> 
<img src=".\image\Snipaste_2023-07-23_08-19-46.jpg" width=450/> 
<img src=".\image\Snipaste_2023-07-23_08-19-56.jpg" width=450/>        
</center>

##### MTCNN中能检测到部分人脸，为什么？

训练过程中包含对部分样本的训练，部分样本是由正样本做了一定的偏移处理生成的，并且训练样本的坐标标签采用偏移量作为标签。

##### 为什么卷积网络具有空间依赖性？

卷积神经网络（Convolutional Neural Networks，CNN）具有空间依赖性，主要是因为它们使用卷积操作来处理输入数据。卷积操作是一种局部操作，它在输入数据的一个小区域（也称为感受野）上进行，这使得卷积神经网络能够捕捉到输入数据中的局部空间依赖性。

在卷积操作中，一个卷积核（或滤波器）在输入数据上滑动，每次滑动都会对当前位置的输入数据和卷积核进行点积运算。这种操作方式使得卷积神经网络能够在处理图像等具有空间结构的数据时，有效地提取出局部特征，并保持这些特征的空间关系。

##### 为什么人脸识别不是一个简单的分类网络？

<font Color=Blue>类别数量不固定：</font>在传统的分类任务中，类别数量是预先定义好的，例如猫狗分类任务就只有两个类别。但在人脸识别任务中，每个人的脸都是一个单独的类别，而且随着新用户的加入，类别数量会不断增加。

<font Color=Blue>类内差异大：</font>同一个人在不同的光照、角度、表情下，其脸部图像的差异可能会很大，这增加了人脸识别的难度。

<font Color=Blue>类间差异小：</font>不同人之间的脸部图像可能存在很高的相似度，例如双胞胎或者具有相似特征的不同人。

##### P网络为什么设计为全卷积网络，而R、O网络为什么使用全连接？

① 因为图像中目标的个数和大小是不确定的，使用全卷积网络，目标的个数可以通过特征图的格子数表示出来。R、O网络使用全连接是因为R、O网络的输入是固定的，要么有人脸，要么没有人脸，使用全连接也可以更方便的进行特征融合。不过也可以使用卷积，只不过没有全连接方便。

##### 为什么P、R网络中没有使用到Landmark，为什么还要输出Landmark？

神经网络在学习多项有关联的任务时，可以相互促进。

① 训练Landmark的同时也给网络提供了标签，对于网络来说，标签信息越丰富，网络学习到的特征信息就越多。

② 关键点的回归和置信度、回归框有一定的关联，例如关键点一定在框内。

##### 为什么MTCNN中P、R、O网络中这么浅的网络还要大量使用最大池化？

因为MTCNN中三个网络的模型都很浅，特征提取能力很差，在网络中存在大量的噪声，使用最大池化能够有效的去除噪声，并且由于是级联任务，所以也能保证精度。

##### MTCNN为什么不适合做通用目标检测？

① MTCNN只对接近正方形物体的检测效果好。首先从训练上看，如果要检测行人，使用正方形去框势必会造成多框了很多噪声，并且有可能框中更多个人，这样在检测时模型只会输出置信度最高的那个，那么就会造成丢目标。其次从侦测上看MTCNN P网络中的检测框是12×12的，经过P网络检测后输出的框反算回原图虽然有一个偏移，但是基本上也是在正方形附近，如果物体不是接近正方形的那么就框不中。

② MTCNN模型太浅，特征提取能力不强，无法很好的处理多分类问题。

##### MTCNN中为什么标签是0、1但是输出是0-1之间的值？如何理解？

我们做标签时，在MTCNN中只有两种可能，是目标或这不是目标，是目标不是目标是一个确定的事件。而我们做训练和侦测时，输入经过神经网络的输出是一个不确定的事件，当我们网络模型训练的越好，那么输出的值越接近0和1。举例：抛硬币事件，正面：1/2，但是事实上我们抛10次硬币，正面概率并非是1/2，只有当我们抛的次数足够多时，才会等于1/2。

#### YOLO

##### YoloV3

<img src=".\image\微信图片_20230723091701.jpg" alt="微信图片_20230723091701" style="zoom:100%;" />

###### 以十分类为例阐释说明yolo系列模型是如何进行目标检测的？

<font Color=Red>标签问题：</font>yolov3原始标签格式为txt：(cls，cx，cy，w，h)，在dataset类中将标签处理为：[c，cx_offset，cy_offset，np.log(p_w)，np.log(p_h)，1，0，0，0，0，0，0，0，0，0]

其中：① c（置信度）计算：标签框和建议框的IOU得到。② 偏移量计算：中心点x的坐标乘以特征图的大小再除以原图大小，整数部分作为索引，小数部分作为偏移量。

<font Color=Red>检测概述：</font>输入一批（N，608，608，3）的图片，输出形状为（N，3，15，H，W），其中3代表的是三种不同形状的建议框，15由[c，cx_offset，cy_offset，np.log(p_w)，np.log(p_h)，1，0，0，0，0，0，0，0，0，0]构成，H、W根据不同的侦测头输出不同的尺寸。yolov3中认为小目标更难检测，所以76×76×255的侦测头要经过更多的卷积层，为了提取到更加丰富的特征。对于每个侦测头特征图上的每一个格子来说，目标中心点落到该格子内，那么就由该格子去检测该格子映射回原图的区域的目标，并且每一个格子内含有三种建议框，通过一个阈值和NMS去重选取得到唯一的置信度最大的检测框。

###### yolo中假如两个目标中心点重合（除完全重合）能否正确检测？

可以正确检测。因为特征图上每个格子会预测三个形状不同的建议框，即便中心点重合，形状不同，也就代表了不是同一个目标，只要大于设定阈值，并且通过nms同类去重就能够被正确检测出来。

###### yolo和MTCNN中是如何进行坐标反算的？反算公式是什么？

YOLO中坐标形式：（cx，cy，h，w），MTCNN中坐标形式：（x1，y1，x2，y2）

MTCNN形式采用的是两个坐标点确定框的大小和位置。当滑动窗口所在格子仅仅包含一个坐标位置，那么就不能反映目标的位置和大小就不能检测出目标，所以设置图像金字塔不断缩放，并且以一个小的步长滑动这样就能确保不漏掉目标。但是导致后果就是计算量大大的增加。

YOLO形式采用的是中心点确定目标的位置，建议框确定目标的大小。这样在滑动窗口时只要有中心点的坐标就能确定目标位置，目标大小通过预测框的偏移量+建议框确定。

###### yolo确定目标的时候为什么不直接取IOU也就是置信度最大的作为最终检测到的目标？

① 目标的个数不确定，可能有多个目标也可能没有目标，如果只取置信度IOU最大的作为目标，那么就丢失或误判了其他目标。

② 目标的类别也不确定，如果只取最大的IOU，那么会只会得到一个类别的目标。

##### YoloV4

<img src=".\image\微信图片_202307230917011.jpg" alt="微信图片_202307230917011" style="zoom:25%;" />

###### CSPDarkNet53

增加了网络层数，增强了网络的特征提取能力。

###### CBM

CBM模块使用了Mish激活函数，① 综合了Relu和Tanh两种激活函数的优势，在输入＞0反向求导迅速并且不会梯度消失，在输入＜0有很强的非线性表达能力。

###### Data Augmentation

随机裁剪和缩放：这种方法可以通过随机裁剪和缩放图像来增加模型的鲁棒性。

随机旋转和翻转：这种方法通过随机旋转和翻转图像来增加模型的鲁棒性。

色彩抖动：这种方法通过随机改变图像的色彩来增加模型的鲁棒性。

CutOut：CutOut通过将某些随机图片切除一部分随机区域，并且用0填充。这种方法通过在图像中随机删除一部分像素来增加模型的鲁棒性。

CutMix：CutMix随机裁剪图像的区域大小，不填充0而是随机选择其他样本经过翻转、缩放、灰度变化后的裁剪区域大小填充。

优点：① 训练数据无非信息像素。

​			② 保留了dropout的优势，体现在四个象限的图片都是其原始图片的部分区域。

​			③ 具有一定的局部识别能力并且左右翻转、缩放、灰度变化等增强了模型的推理能力。

MixUp：MixUp通过随机将多张图片以一定的比例进行融合。这是一种通过线性插值的方式将两个图像和它们的标签混合在一起的数据增强方法。

Mosaic：马赛克增强参考了CutMix数据增强方式。

步骤：① 从训练样本中随机取出4张图片。

​			② 构建背景底图，通常是输入图像大小的两倍。

​			③ 将选定的四个图像裁剪和缩放、翻转到新图像的四个象限中。

​			④ 对于每个图像，需要调整其标签的坐标，以便它们与新的图像大小和位置相匹配。

优点：① 扩充了数据集、增加了小目标数据的样本量。

​			② 使得训练数据中的小样本更小，能侦测到更小的目标。

​			③ BN能一次性统计更多图片的参数。

###### SPP

通过对特征图进行不同大小的池化，获得了不同大小的感受野，最后进行维度上的拼接，获取到不同尺度的特征融合信息，从而提升模型性能。

###### IOU Loss和SmoothL1 Loss

yolov4中提出了IOU Loss和SmoothL1 Loss，见上文《常见损失函数优缺点》

yolov4中训练损失采用的是CIOU Loss+SmoothL1 Loss的加权组合，而在nms中使用的是DIOU Loss。经典nms算法中，IOU是唯一考量的因素。但是在实际应用场景中，当两个不同物体挨得很近时，由于IOU值比较大，往往经过nms处理后，只剩下一个检测框，这样导致漏检的错误情况发生。基于此，DIOU-NMS就不仅仅考虑IOU，还考虑两个框中心点之间的距离。如果两个框之间IOU比较大，但是两个框的距离比较大时，可能会认为这是两个物体的框而不会被过滤掉。 

###### 侦测头

yolov4中侦测头反了过来，大的目标在检测时会经过更深的网络，是因为，作者认为大目标更难检测。原因如下：

① 首先由于yolov4中引用了马赛克增强间接的增大了训练样本中的小目标数据占整体样本数据量的权重，导致yolov4更加偏向于检测小目标。

② 其次，由于大目标有更大的建议框，模型预测的偏移量较小的误差反算回原图之后也会放大该误差，导致预测不准确。

##### YoloV5

<img src=".\image\微信图片_202307230917012.jpg" alt="微信图片_202307230917012" style="zoom:40%;" />

###### Fcous

Fcous具体操作是在一张图片中每隔一个像素拿到一个值，类似于邻近下采样，这样就拿到了四张图片，四张图片互补，长的差不多，但是没有信息丢失，这样一来，将W、H信息就集中到了通道空间，输入通道扩充了4倍，即拼接起来的图片相对于原先的RGB三通道模式变成了12个通道，最后将得到的新图片再经过卷积操作，最终得到了没有信息丢失情况下的二倍下采样特征图。

优点：① 降低了模型参数量和计算量	② 增大了模型感受野

![Snipaste_2023-08-01_20-39-23](C:\Users\Administrator\Desktop\学习文档\学习总结\image\Snipaste_2023-08-01_20-39-23.png)

### 跟踪模型

#### DeepSort

<img src=".\image\Snipaste_2023-07-23_17-42-27.jpg" alt="Snipaste_2023-07-23_17-42-27" style="zoom:50%;" />

DeepSORT（Deep Learning-based SORT）是一种基于深度学习的目标跟踪算法，用于在视频中对目标进行准确的跟踪和识别。其原理是结合了目标检测和深度学习特征提取的方法，并使用卡尔曼滤波器进行目标跟踪。

DeepSORT的主要步骤如下：
① 目标检测。使用目标检测算法（如YOLO、Faster R-CNN等）来检测视频帧中的目标，并获取它们的边界框。
特征提取。对于每个检测到的目标，使用深度学习模型（如卷积神经网络）来提取其特征表示。这些特征表示可以捕捉目标的外观和语义信息。
② 目标关联。使用卡尔曼滤波器来对目标进行关联和跟踪。卡尔曼滤波器可以根据当前的目标位置和速度预测下一帧中的目标位置，并根据测量值（即目标检测结果）进行修正。
③ 数据关联。通过计算目标特征之间的相似度，将当前帧中的目标与上一帧中的目标进行关联。这可以通过计算特征之间的距离或使用匈牙利算法来实现。
④ 目标识别。对于已经关联的目标，可以使用目标识别算法（如Siamese网络）来进行目标的身份识别，从而在跟踪过程中保持目标的一致性。
⑤ 更新和输出。根据目标的跟踪结果，更新卡尔曼滤波器的状态，并输出跟踪结果，包括目标的位置、速度和身份信息。

##### 基础知识

<font Color=green>卡尔曼滤波算法：</font>卡尔曼滤波算法是一种用于估计系统状态的递归滤波算法。它基于状态空间模型，通过融合系统的动态模型和观测数据，对系统的状态进行最优估计。卡尔曼滤波算法假设系统的状态和观测数据都服从高斯分布，并通过最小化均方误差来进行状态估计。

卡尔曼所估计的状态向量是一个8维向量x=[cx,cy,r,h,vx,vy,vr,vh]。即中心坐标，宽高比r，高h以及各自的速度变化值。

<font Color=green>匈牙利算法：</font>匈牙利算法是一种用于解决指派问题（Assignment Problem）的优化算法。在DeepSORT中，匈牙利算法用于将当前帧中的目标与上一帧中的目标进行关联，以实现目标的数据关联。

具体原理参考博客：

[(68条消息) 目标追踪---deepsort原理讲解_炮哥带你学的博客-CSDN博客](https://blog.csdn.net/didiaopao/article/details/120272947?spm=1001.2014.3001.5506)

https://www.bilibili.com/video/BV1L24y1H78j?p=37&vd_source=6bf8a2ceef58918e445129ceac9c7256

## 五、Linux

### Linux基础命令

Linux常用命令大全 https://blog.csdn.net/m0_62808124/article/details/127540625

### Docker应用

#### 使用docker快速构建深度学习环境

① 一键安装docker

```
wget http://fishros.com/install -O fishros && . fishros
```

② 如果需要使用带有cuda的容器，那么需要先安装NVIDIA Container Toolkit

```python
# 我使用的是Ubuntu 20.04LTS
# 打开终端，首先设置变量
distribution=$(. /etc/os-release;echo $ID$VERSION_ID)
# 安装公钥
curl -s -L https://nvidia.github.io/nvidia-docker/gpgkey | sudo apt-key add -
# 获取list
curl -s -L https://nvidia.github.io/nvidia-docker/$distribution/nvidia-docker.list | sudo tee /etc/apt/sources.list.d/nvidia-docker.list

# 更新
sudo apt update
# 安装nvidia-container-toolkit
sudo apt install nvidia-container-toolkit
# 重启
sudo systemctl restart docker
```

③ 进入[hub.docker.com](https://hub.docker.com/)，查看cuda-pytorch镜像（需要翻墙访问，没有注册需要先注册）。一般使用pytorch/pytorch社区下的官方镜像就行了。也可以在终端中使用docker search 内容 来搜寻镜像，但是不推荐，因为往往找不到合适的。

<img src="C:\Users\Administrator\Desktop\学习文档\学习总结\image\Snipaste_2023-08-04_10-02-52.png" alt="Snipaste_2023-08-04_10-02-52" style="zoom:55%;" />



④ 使用上图右边有对应的docker pull pytorch/pytorch......拉取镜像代码，复制改代码在终端运行即可自动拉取镜像。

⑤ 拉取下来之后使用下述代码创建容器并进入。

```python
docker run -it --gpus all --name [命名你的容器名] 镜像名：Tag版本
# 这是最简单的运行容器方式，也可以使用其他参数设置挂载、后台运行等等，使用docker run --help可以查看详细内容，或者去博客上找。

# 第一次创建容器会自动进入，以后进入可以使用以下代码.
# 查看是否正在运行
docker ps -a
# 如果没在运行，使用以下代码运行容器。
docker start 容器ID
# 如果已经在运行，使用以下代码进入容器。
docker exec -it 容器名 bash
```

⑥ 查看能否使用cuda

```python
# 查询GPU状态和配置
nvidia-smi
# 查询CUDA编译版本和驱动
nvcc -V
# 如果上述两个都能有正常输出，大概是没问题了，不过最好再检查一下torch.cuda.is_available()输出是否为True
python
import torch
print(torch.cuda.is_available())
```

如果要在docker容器中训练模型会涉及一些文件传输等其他操作，我觉得只需要在创建容器的时候使用-v参数挂载ubuntu下目录到容器中就行了，然后再将程序文件放到Ubuntu指定目录就可以了，但是我还没尝试，不过应该不难。

## 六、OpenCv

### 数字图像处理基础

<font Color=Red>数字图像：</font>数字图像可以理解为是图像的数字化表示，它是由一系列离散单元经过量化后形成的灰度值的集合，即像素。

数字图像处理包含图像变换、图像增强、图像复原和重建等内容，本文主要讲解图像增强部分。

<img src=".\image\Snipaste_2023-07-19_08-53-12.jpg" style="zoom:30%;" />

#### 空域法

##### 点操作

<font Color=Blue>图像求反：</font>图像求反与图像算术运算中的非（not）运算相同，是对每个像素值进行255-piexl的操作。

<font Color=Blue>动态范围压缩：</font>包含线性方法和非线性方法。线性方法主要是Y=aX+b的一次函数形式，a决定对比度，b决定亮度。非线性方法主要包括对数变换和指数变换，对数变换形式：Y=γlog(1+x)，γ决定对比度。指数变换（γ变换）形式：Y=cx^γ，c灰度缩放系数，γ控制缩放程度。

<img src=".\image\Snipaste_2023-07-25_09-09-29.jpg" alt="Snipaste_2023-07-25_09-09-29" style="zoom:50%;" />

线性变换和非线性变换本质上就是对图像像素值的重映射，使原像素不同位置、不同程度的像素值有不同比例的变化。

##### 模板操作

<font Color=Blue>低通滤波（图像平滑）：</font>频率低的分量像素值梯度均匀连续。

① 均值滤波 cv2.blur()，cv2.boxFilter()	② 高斯滤波 cv2.GaussianBlur()	③ 中值滤波 cv2.medianBlur()	

④ 双边滤波cv2.bilateralFilter()	⑤ 自定义卷积核低通滤波 cv2.filter2D()

<font Color=Blue>高通滤波（图像锐化）：</font>频率高的分量像素值梯度陡峭变化大，通常指图像中的一些噪点、边缘信息。

① 拉普拉斯算子：cv2.Laplacian()	② Sobel算子：cv2.Sobel()	③ Scharr算子：cv.Scharr()	④ Roberts算子：cv2.filter()

⑤ 钝化掩蔽：钝化掩蔽的实现过程是：（1）对原始图像进行平滑处理，得到平滑图像；（2）从原始图像中减去平滑图像，产生掩蔽模板；（3）将原始图像与掩蔽模板加权相加，得到钝化掩蔽。

#### 频域法

① 低通滤波	② 高通滤波	③ 带阻滤波	④ 带通滤波

频率域滤波在OpenCV Python中的步骤如下：

① 将输入图像转换为灰度图像（如果不是灰度图像）。
② 对灰度图像进行零均值化，通过将每个像素值减去图像的均值来实现。
③ 使用二维快速傅里叶变换（FFT）将零均值化的图像转换为频率域表示。
④ 构建一个滤波器，可以是低通滤波器、高通滤波器或其他类型的滤波器。
⑤ 将滤波器应用于频率域表示的图像，通过将滤波器与频率域图像进行点乘。
⑥使用逆傅里叶变换（IFFT）将滤波后的频率域图像转换回空域表示。
⑦ 对逆变换后的图像进行反零均值化，通过将每个像素值加上图像的均值来实现。
⑧ 可选：对结果图像进行进一步的后处理，如阈值处理或图像增强。
⑨ 输出滤波后的图像作为最终结果。

频率域滤波：[(68条消息) Python3+OpenCV（八）：频率域滤波增强_opencv通过频域设计滤波器平滑增强图像的代码_Miraitowa_x的博客-CSDN博客](https://blog.csdn.net/Seven_WWW/article/details/109754158)

数字图像处理优秀博客：[(68条消息) 【OpenCV 例程200篇】62. 图像锐化——钝化掩蔽_youcans_的博客-CSDN博客](https://blog.csdn.net/youcans/article/details/122034827)

### 形态学处理

<font Color=Blue>腐蚀：</font>cv2.erode()

<font Color=Blue>膨胀：</font>cv2.dilatie()

<font Color=Blue>开运算：</font>先腐蚀再膨胀。cv2.morphologyEx(cv2.MORPH_OPEN)

<font Color=Blue>闭运算：</font>先膨胀再腐蚀。cv2.morphologyEx(cv2.MORPH_CLOSE)

<font Color=Blue>礼帽：</font>原始输入-开运算。cv2.morphologyEx(cv2.MORPH_TOPHAT)

<font Color=Blue>黑帽：</font>闭运算-原始输入。cv2.morphologyEx(cv2.MORPH_BLACKHAT)

### 图像特征与目标检测

OpenCv中文文档：http://www.woshicver.com/

## 七、机器学习常见算法

### 普通分类和回归

#### KNN（分类回归）

<font Color=Red>原理：</font>KNN算法基于实例之间的相似性进行预测。对于分类任务，KNN算法将新样本的类别标签预测为其K个最近邻居中最常见的类别。对于回归任务，KNN算法将新样本的目标值预测为其K个最近邻居的平均值。

① 准备数据集，包括特征和对应的类别标签（分类任务）或目标值（回归任务）。
② 选择一个合适的距离度量方法，如欧氏距离或曼哈顿距离。
③ 对于每个待预测样本，计算其与训练集中所有样本的距离。
④ 根据距离选择K个最近邻居。
⑤ 对于分类任务，根据K个最近邻居的类别标签，预测待预测样本的类别为最常见的类别。对于回归任务，预测待预测样本的目标值为K个最近邻居的目标值的平均值。

KNN是一种监督学习的算法

#### SVM(分类回归)

<font Color=Red>原理：</font>SVM的目标是找到一个最优的超平面，将不同类别的样本分隔开来。对于分类任务，SVM通过最大化类别间的间隔来寻找最优超平面。对于回归任务，SVM通过在样本点周围构建一个边界带来拟合目标值。

① 准备数据集，包括特征和对应的类别标签（分类任务）或目标值（回归任务）。
② 选择一个合适的核函数（如线性核、多项式核或高斯核），或者使用线性SVM。
③ 根据选择的核函数或线性SVM，将数据映射到高维特征空间。
④ 对于分类任务，通过最大化类别间的间隔，找到一个最优的超平面。对于回归任务，通过在样本点周围构建一个边界带来拟合目标值。
⑤ 根据超平面或边界带，对新样本进行预测。对于分类任务，根据新样本的位置来判断其所属类别。对于回归任务，根据新样本的位置来预测其目标值。

SVM是一种监督学习的算法

<img src="C:\Users\Administrator\Desktop\学习文档\学习总结\image\Snipaste_2023-08-02_09-44-18.png" alt="Snipaste_2023-08-02_09-44-18" style="zoom:70%;" />

#### K-Means（聚类）

<font Color=Red>原理：</font>K-Means算法是一种无监督学习算法，用于将数据集划分为K个不同的簇。其原理是通过最小化数据点与所属簇中心的距离来确定簇的边界。

① 选择K个初始的簇中心点，可以是随机选择或根据数据分布选择。
② 对于每个数据点，计算其与每个簇中心的距离，并将其分配给距离最近的簇。
③ 更新每个簇的中心点，将其设置为该簇中所有数据点的平均值。
④ 重复步骤2和步骤3，直到簇中心不再发生变化或达到预定的迭代次数。
⑤ 返回最终的簇划分结果。

K-Means是一种无监督学习算法

#### 朴素贝叶斯（分类回归）

<font Color=Red>原理：</font>朴素贝叶斯分类回归算法是一种基于贝叶斯定理的概率模型，用于分类和回归任务。其原理是基于特征之间的条件独立性假设，通过计算后验概率来进行分类或回归预测。

① 准备数据集，包括特征和对应的类别标签（分类任务）或目标值（回归任务）。
② 根据数据集计算每个类别的先验概率，即每个类别在数据集中的出现频率。
③ 对于分类任务，对于每个特征，计算在给定类别下的条件概率，即特征在该类别下的出现频率。对于回归任务，计算每个特征在目标值上的条件概率。
④ 对于待预测样本，根据贝叶斯定理计算其属于每个类别的后验概率。对于分类任务，选择具有最高后验概率的类别作为预测结果。对于回归任务，根据后验概率的加权平均值来预测目标值。
⑤ 返回预测结果。

朴素贝叶斯是一种有监督学习算法

#### 决策树（ID.3,C4.5）

<font Color=Red>原理：</font>决策树分类回归算法是一种基于树结构的监督学习算法，用于分类和回归任务。其原理是通过构建一棵树来对数据进行划分，每个内部节点表示一个特征，每个叶节点表示一个类别或目标值。

① 准备数据集，包括特征和对应的类别标签（分类任务）或目标值（回归任务）。
② 选择一个合适的划分准则，如信息增益、基尼指数或均方误差。
③ 根据选择的划分准则，选择最佳的特征作为当前节点的划分特征。
④ 将数据集根据划分特征的取值分成多个子集，每个子集对应一个子节点。
⑤ 对于每个子节点，重复步骤2到步骤4，直到满足停止条件（如达到最大深度、节点中的样本数小于阈值）或无法继续划分。
⑥ 对于分类任务，将叶节点标记为该节点中样本数最多的类别。对于回归任务，将叶节点标记为该节点中样本目标值的平均值。
⑦ 返回决策树。

决策树决策节点的选择通常使用信息增益、信息增益比、基尼系数。

<font Color=Blue>信息增益（ID.3中）：</font>在决策树中，信息增益是一种用于选择最佳划分特征的准则。它衡量了使用某个特征来划分数据集后，所获得的信息的增加量。信息增益通过计算划分前后的信息熵之差来衡量使用某个特征进行划分后的信息增加量。具体计算步骤如下：

① 计算划分前的信息熵，即整个数据集的信息熵。
② 对于每个可能的特征值，计算使用该特征进行划分后的信息熵。
③ 根据每个特征值划分后的信息熵和对应的样本数，计算加权平均的信息熵。
④ 计算信息增益，即划分前的信息熵减去加权平均的信息熵。

选择信息增益最大的特征作为当前节点的划分特征，即认为该特征能够提供最大的信息增加量，从而更好地区分不同类别的样本。

<font Color=Blue>信息增益比（C4.5中）：</font>在决策树中，除了信息增益外，还有一种准则叫做信息增益比。信息增益比是信息增益除以划分特征的固有信息，用于解决信息增益偏向于具有较多取值的特征的问题。信息增益比 = 信息增益 / 划分特征的固有信息。

划分特征的固有信息是指划分特征的取值的多样性，可以使用熵或基尼指数等度量来表示。通过使用信息增益比准则，可以更好地平衡划分特征的多样性和信息增益之间的关系。当划分特征的固有信息较大时，信息增益比会减小，从而降低对具有较多取值的特征的偏好。在决策树算法中，可以使用信息增益比来选择最佳的划分特征，从而构建更具有泛化能力的决策树模型。 

<font Color=Blue>决策树优缺点：</font>易解释、速度快、原理简单。容易过拟合、准确度不如其他模型。

由于决策树是考虑了所有的数据点而生成的复杂树，通常容易造成过拟合。为了解决过拟合，决策树需要剪枝。剪枝分为预剪枝和后剪枝。但是要注意预剪枝由于提前停止了树的生长，可能导致欠拟合。而使用后剪枝，则会造成较高的时间成本。

<font color=blue>预剪枝：</font>① 当树的深度达到一定的规模，则停止生长。

​			   ② 达到当前节点的样本数量小于某个阈值的时候。

​	           ③ 计算每次分裂对测试集的准确性提升，当小于某个阈值，或不再

​			   ④ 提升甚至有所下降时，停止生长。

​               ⑤ 当信息增益，增益率和基尼指数增益小于某个阈值的时候不在生长。

<font color=blue>后剪枝：</font>① 错误率降低剪枝	② 最小代价损失剪枝

本文以西瓜书为例，错误率降低剪枝（REP）。

将数据分为训练集和测试集，用训练集去生成一颗完整的决策树，用测试集去剪枝。

该算法将树上的每个节点都作为剪枝的候选对象，通过如下步骤进行剪枝操作：
step1：删除以此节点为根节点的树，
step2：使其成为叶子结点，赋予该节点最常见的分类
step3：对比删除前和删除后的性能是否有所提升，如果有则进行删除，没有则保留。

优秀博客：[剪枝决策树原理与Python实现 - Chiak1 - 博客园 (cnblogs.com)](https://www.cnblogs.com/violet-egar/p/14325648.html)

#### 岭回归

<font Color=Red>原理：</font>岭回归是一种用于处理多重共线性问题的线性回归算法。其原理是在普通最小二乘法的基础上引入了正则化项，通过限制模型参数的大小来减小参数估计的方差。

① 准备数据集，包括特征和对应的目标值。
② 对特征进行标准化处理，使其均值为0，方差为1，以避免不同特征之间的量纲差异对模型的影响。
③ 设置岭回归的正则化参数λ，用于控制正则化项的强度。
④ 构建岭回归模型，通过最小化带有正则化项的损失函数来估计模型参数。
⑤ 使用交叉验证或其他方法选择最佳的正则化参数λ。
⑥ 根据估计的模型参数进行预测。

### 集成学习

#### boosting

<font Color=green>概念：</font>通过迭代训练一系列弱学习器，每个学习器都尝试修正前一个学习器的错误，最终将它们组合成一个强学习器。

##### Adaboost

<font Color=Red>原理：</font>Adaboost（自适应增强）是一种集成学习算法，用于提高弱分类器的性能。其原理是通过迭代训练一系列弱分类器，并根据分类错误的样本调整样本权重，使得后续的弱分类器更加关注分类错误的样本。

**步骤**：
① 准备数据集，包括特征和对应的类别标签。
② 初始化样本权重，使得每个样本的权重相等。
③ 对于每个迭代轮次：
	训练一个弱分类器，通常使用简单的分类算法，如决策树桩（仅有一个分裂节点的决策树）。
	根据弱分类器的分类结果和实际类别标签，计算分类错误的样本权重之和。
	根据分类错误的样本权重之和，更新每个样本的权重，使得分类错误的样本权重增加，分类正确的样本权重减少。
	根据更新后的样本权重，重新计算每个样本的权重归一化系数，以确保样本权重之和为1。
④ 根据每个弱分类器的分类准确度，计算其权重，使得分类准确度高的弱分类器具有较大的权重。
⑤ 将所有弱分类器组合成一个强分类器，通过加权投票或加权平均来进行分类预测。
⑥ 返回Adaboost的预测结果。

<img src="C:\Users\Administrator\Desktop\学习文档\学习总结\image\Snipaste_2023-07-27_14-48-51.png" alt="Snipaste_2023-07-27_14-48-51" style="zoom:50%;" />

##### GBDT

<font Color=Red>原理：</font>梯度提升树（Gradient Boosting Decision Tree，GBDT）是一种集成学习算法，通过迭代地训练一系列决策树来提高模型的性能。其原理是通过梯度下降的方法，每次迭代都尝试拟合前一个模型的残差，从而逐步减小预测误差。最终将这些决策树组合成一个强学习器，用于进行预测。

① 准备数据集，包括特征和对应的目标值。
② 初始化模型，通常使用一个简单的模型作为初始模型，如平均值或常数。
③ 对于每个迭代轮次：
	计算当前模型的预测值与实际目标值之间的残差。
	使用残差作为目标值，训练一个新的决策树模型。
	根据学习率（learning rate）乘以新模型的预测结果，更新当前模型的预测值。
④ 将所有决策树组合成一个强学习器，通过加权平均或加权投票来进行预测。
⑤ 返回GBDT的预测结果。

#### bagging

<font Color=green>概念：</font>通过随机有放回地抽样生成多个训练集，每个训练集用于训练一个独立的学习器，最终将它们组合成一个强学习器。

##### 随机森林（分类回归）

<font Color=Red>原理：</font>随机森林是一种集成学习算法，通过构建多个决策树并进行投票或平均来进行分类或回归。其原理是通过随机选择特征子集和样本子集来构建决策树，从而减少过拟合并提高模型的泛化能力。
① 准备数据集，包括特征和对应的类别标签（分类任务）或目标值（回归任务）。
② 对于每棵决策树：
	随机选择一个特征子集，通常是从所有特征中随机选择一部分特征。
	随机选择一个样本子集，通常是从原始数据集中有放回地随机选择一部分样本。
③ 使用选定的特征子集和样本子集构建一棵决策树，可以使用信息增益、基尼指数等准则进行划分。
④ 对于分类任务，通过投票来确定最终的预测结果，即选择多数决策树预测的类别作为最终结果。对于回归任务，通过平均决策树的预测值来得到最终的预测结果。
⑤ 返回随机森林的预测结果。

<font Color=Blue>优点：</font>是能够处理高维数据和大规模数据集，具有较好的泛化能力和鲁棒性。它能够减少过拟合问题，并且对于缺失值和异常值具有一定的鲁棒性。在使用随机森林算法时，需要根据具体问题选择合适的决策树数量和参数设置，以及进行特征工程以提高模型的性能。 

#### stacking

<font Color=green>概念：</font>通过将多个不同类型的学习器组合在一起，将它们的预测结果作为输入，再训练一个元学习器来进行最终的预测。

这些集成学习方法的共同目标是通过组合多个学习器的预测结果来提高整体模型的性能。它们的区别在于学习器之间的关系和组合方式。Boosting通过迭代修正错误来提高性能，Bagging通过平均或投票来减小方差，Stacking通过训练一个元学习器来组合多个学习器的预测结果。

[(9 封私信 / 80 条消息) 集成学习（ensemble learning）应如何入门？ - 知乎 (zhihu.com)](https://www.zhihu.com/question/29036379/answer/2748520277)

## 八、模型部署

### onnxruntime部署

参考博客：[Train_Custom_Dataset/图像分类 at main · TommyZihao/Train_Custom_Dataset (github.com)](https://github.com/TommyZihao/Train_Custom_Dataset/tree/main/图像分类)

### nccc部署

## 九、知识点博客

目标检测几种特征金字塔结构：[SPP，PPM、ASPP和FPN结构理解和总结 - Sanny.Liu-CV&&ML - 博客园 (cnblogs.com)](https://www.cnblogs.com/hansjorn/p/14295889.html)

opencv（python\c++）基础及实战项目：[Opencv项目实战_胖墩会武术的博客-CSDN博客](https://blog.csdn.net/shinuone/category_12219416.html?spm=1001.2014.3001.5482)

 																																																							

​																																																								***<font color=green size=5>Written by  WuTao</font>***                                 																																																																																																																												